{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    " 1. Random Forest\n",
    " 2. Lightgbm\n",
    " 3. Xgboost\n",
    " 4. Catboost\n",
    " 5. Knn\n",
    " 6. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_split2(dataset1, dataset2):\n",
    "    \n",
    "    X1 = dataset1.drop('연봉', axis=1)\n",
    "    column_dict = {f'variable{idx+1}':col for idx, col in enumerate(X1.columns)}\n",
    "    X1 = X1.rename(columns = {col:f'variable{idx+1}' for idx, col in enumerate(X1.columns)})\n",
    "    y1 = dataset1['연봉']\n",
    "    \n",
    "    X2 = dataset2.drop('연봉', axis=1)\n",
    "    X2 = X2.rename(columns = {col:f'variable{idx+1}' for idx, col in enumerate(X2.columns)})\n",
    "    y2 = dataset2['연봉']\n",
    "    \n",
    "    return column_dict, X1, y1, X2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # rf 모델링\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        rf_model = RandomForestRegressor(random_state = 42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(rf_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        rf_model = RandomForestRegressor(random_state = 42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(rf_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # rf 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'rf':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # lgbm 모델링\n",
    "    lgb_params = {\"objective\" : \"rmse\",\n",
    "                 \"verbosity\" : -1}\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :].values\n",
    "        y_train = data_y1[tr_idx].values\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :].values\n",
    "        y_valid = data_y1[val_idx].values\n",
    "\n",
    "        lgb_dtrain = lgb.Dataset(data = X_train, label = y_train) \n",
    "        lgb_dvalid = lgb.Dataset(data = X_valid, label = y_valid) \n",
    "\n",
    "        lgb_model = lgb.train(lgb_params, lgb_dtrain, 20000, valid_sets=[lgb_dvalid], early_stopping_rounds=100, verbose_eval=1000)\n",
    "        \n",
    "        pred_valid = list(lgb_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :].values\n",
    "        y_train = data_y2[tr_idx].values\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :].values\n",
    "        y_valid = data_y2[val_idx].values\n",
    "\n",
    "        lgb_dtrain = lgb.Dataset(data = X_train, label = y_train) \n",
    "        lgb_dvalid = lgb.Dataset(data = X_valid, label = y_valid) \n",
    "\n",
    "        lgb_model = lgb.train(lgb_params, lgb_dtrain, 20000, valid_sets=[lgb_dvalid], early_stopping_rounds=100, verbose_eval=1000)\n",
    "        \n",
    "        pred_valid = list(lgb_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "\n",
    "    # lgbm 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'lgbm':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "    \n",
    "    # xgb 모델링\n",
    "    xgb_final_param = {\n",
    "          \"objective\" : 'reg:squarederror',\n",
    "          \"random_state\" : 42,\n",
    "          \"verbosity\" : 0\n",
    "          }\n",
    "    \n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :].values\n",
    "        y_train = data_y1[tr_idx].values\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :].values\n",
    "        y_valid = data_y1[val_idx].values\n",
    "\n",
    "        xgb_dtrain = xgb.DMatrix(data = X_train, label = y_train) \n",
    "        xgb_dvalid = xgb.DMatrix(data = X_valid, label = y_valid) \n",
    "\n",
    "        xgb_model = xgb.train(params = xgb_final_param, dtrain = xgb_dtrain, num_boost_round = 20000, early_stopping_rounds = 100, verbose_eval = 1000, evals=[(xgb_dtrain, 'train'), (xgb_dvalid,'eval')])\n",
    "\n",
    "        pred_valid = list(xgb_model.predict(xgb.DMatrix(data = X_valid)))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :].values\n",
    "        y_train = data_y2[tr_idx].values\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :].values\n",
    "        y_valid = data_y2[val_idx].values\n",
    "\n",
    "        xgb_dtrain = xgb.DMatrix(data = X_train, label = y_train) \n",
    "        xgb_dvalid = xgb.DMatrix(data = X_valid, label = y_valid) \n",
    "\n",
    "        xgb_model = xgb.train(params = xgb_final_param, dtrain = xgb_dtrain, num_boost_round = 20000, early_stopping_rounds = 100, verbose_eval = 1000, evals=[(xgb_dtrain, 'train'), (xgb_dvalid,'eval')])\n",
    "\n",
    "        pred_valid = list(xgb_model.predict(xgb.DMatrix(data = X_valid)))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # xgb 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'xgb':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # cb 모델링\n",
    "    cat_cols = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        cb_dtrain = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "        cb_dvalid = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "        cb_model = CatBoostRegressor(iterations=20000, eval_metric='RMSE', loss_function='RMSE', verbose = 0)\n",
    "        cb_model.fit(cb_dtrain, eval_set=cb_dvalid, early_stopping_rounds=100, verbose_eval=1000, use_best_model=True)\n",
    "\n",
    "        pred_valid = list(cb_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        cb_dtrain = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "        cb_dvalid = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "        cb_model = CatBoostRegressor(iterations=20000, eval_metric='RMSE', loss_function='RMSE', verbose = 0)\n",
    "        cb_model.fit(cb_dtrain, eval_set=cb_dvalid, early_stopping_rounds=100, verbose_eval=1000, use_best_model=True)\n",
    "        \n",
    "        pred_valid = list(cb_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # cb 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "    \n",
    "    output = pd.DataFrame({'cb':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # knn 모델링\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        knn_model = KNeighborsRegressor()\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(knn_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        knn_model = KNeighborsRegressor()\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(knn_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # knn 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'knn':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # knn 모델링\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        regression_model = LinearRegression()\n",
    "        regression_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(regression_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        regression_model = LinearRegression()\n",
    "        regression_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(regression_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # knn 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'regression':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test분할 후 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitter_fa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver2/타자_fa(모델링용).csv')\n",
    "hitter_nonfa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver2/타자_nonfa(모델링용).csv')\n",
    "pitcher_fa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver2/투수_fa(모델링용).csv')\n",
    "pitcher_nonfa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver2/투수_nonfa(모델링용).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 타자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분할\n",
    "col_dict, X1, y1, X2, y2 = Xy_split2(hitter_fa, hitter_nonfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's rmse: 27310.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's rmse: 22281.3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's rmse: 22987.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's rmse: 28922\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 27681.3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 6444.97\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's rmse: 4924.4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's rmse: 3535.66\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[449]\tvalid_0's rmse: 4531.97\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's rmse: 5511.85\n",
      "[0]\ttrain-rmse:48835.57812\teval-rmse:54600.95703\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-rmse:9027.64941\teval-rmse:27820.57031\n",
      "\n",
      "[0]\ttrain-rmse:51346.82422\teval-rmse:44537.43359\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-rmse:5013.99414\teval-rmse:25643.23828\n",
      "\n",
      "[0]\ttrain-rmse:49234.49219\teval-rmse:54179.29688\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-rmse:865.65875\teval-rmse:28352.17969\n",
      "\n",
      "[0]\ttrain-rmse:48988.35547\teval-rmse:57510.89453\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[110]\ttrain-rmse:90.41217\teval-rmse:33197.70703\n",
      "\n",
      "[0]\ttrain-rmse:50160.83203\teval-rmse:49484.98047\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[136]\ttrain-rmse:38.30607\teval-rmse:25057.60352\n",
      "\n",
      "[0]\ttrain-rmse:8893.32910\teval-rmse:10438.10059\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-rmse:489.26556\teval-rmse:6222.55908\n",
      "\n",
      "[0]\ttrain-rmse:9338.53711\teval-rmse:8619.21973\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[52]\ttrain-rmse:372.22739\teval-rmse:4061.27710\n",
      "\n",
      "[0]\ttrain-rmse:9460.69727\teval-rmse:8583.98926\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-rmse:679.53613\teval-rmse:3127.05713\n",
      "\n",
      "[0]\ttrain-rmse:9271.19922\teval-rmse:9832.55566\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[116]\ttrain-rmse:58.38975\teval-rmse:4547.89111\n",
      "\n",
      "[0]\ttrain-rmse:8985.01953\teval-rmse:10492.12207\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[31]\ttrain-rmse:515.63751\teval-rmse:5656.11377\n",
      "\n",
      "Learning rate set to 0.006968\n",
      "0:\tlearn: 51565.9013111\ttest: 55084.0278246\tbest: 55084.0278246 (0)\ttotal: 138ms\tremaining: 45m 54s\n",
      "1000:\tlearn: 16524.1937387\ttest: 28894.8494750\tbest: 28894.8494750 (1000)\ttotal: 4.4s\tremaining: 1m 23s\n",
      "2000:\tlearn: 10993.2159162\ttest: 27548.2041502\tbest: 27547.8597119 (1999)\ttotal: 8.4s\tremaining: 1m 15s\n",
      "3000:\tlearn: 7455.8209796\ttest: 27078.7495454\tbest: 27075.8245207 (2990)\ttotal: 12.5s\tremaining: 1m 10s\n",
      "4000:\tlearn: 5246.5923979\ttest: 26918.5416660\tbest: 26918.4792374 (3999)\ttotal: 16.6s\tremaining: 1m 6s\n",
      "5000:\tlearn: 3665.2057965\ttest: 26825.7967875\tbest: 26825.5316900 (4997)\ttotal: 20.8s\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 26812.65359\n",
      "bestIteration = 5198\n",
      "\n",
      "Shrink model to first 5199 iterations.\n",
      "Learning rate set to 0.006968\n",
      "0:\tlearn: 54106.5377826\ttest: 44279.7881432\tbest: 44279.7881432 (0)\ttotal: 4.76ms\tremaining: 1m 35s\n",
      "1000:\tlearn: 16786.8454826\ttest: 23784.6106510\tbest: 23784.6106510 (1000)\ttotal: 4.5s\tremaining: 1m 25s\n",
      "2000:\tlearn: 10444.5145473\ttest: 22846.0919962\tbest: 22840.1932762 (1990)\ttotal: 8.76s\tremaining: 1m 18s\n",
      "3000:\tlearn: 7065.1512337\ttest: 22504.9331529\tbest: 22503.9808721 (2999)\ttotal: 13.1s\tremaining: 1m 14s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22427.40137\n",
      "bestIteration = 3440\n",
      "\n",
      "Shrink model to first 3441 iterations.\n",
      "Learning rate set to 0.006968\n",
      "0:\tlearn: 51546.7495311\ttest: 55166.9491595\tbest: 55166.9491595 (0)\ttotal: 4.91ms\tremaining: 1m 38s\n",
      "1000:\tlearn: 16777.2389297\ttest: 24840.2658165\tbest: 24839.1091599 (998)\ttotal: 4.9s\tremaining: 1m 32s\n",
      "2000:\tlearn: 11021.0386959\ttest: 23213.9001931\tbest: 23213.9001931 (2000)\ttotal: 9.64s\tremaining: 1m 26s\n",
      "3000:\tlearn: 7619.0076738\ttest: 22854.2277787\tbest: 22850.2997501 (2990)\ttotal: 14.9s\tremaining: 1m 24s\n",
      "4000:\tlearn: 5479.1054736\ttest: 22668.0166996\tbest: 22664.7912855 (3946)\ttotal: 19.7s\tremaining: 1m 18s\n",
      "5000:\tlearn: 3882.6231192\ttest: 22570.7513726\tbest: 22569.1457269 (4979)\ttotal: 24.6s\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22534.20745\n",
      "bestIteration = 5714\n",
      "\n",
      "Shrink model to first 5715 iterations.\n",
      "Learning rate set to 0.006968\n",
      "0:\tlearn: 51479.7898097\ttest: 55424.9637800\tbest: 55424.9637800 (0)\ttotal: 4.69ms\tremaining: 1m 33s\n",
      "1000:\tlearn: 16497.5595117\ttest: 28434.3019751\tbest: 28434.3019751 (1000)\ttotal: 5.26s\tremaining: 1m 39s\n",
      "2000:\tlearn: 10909.8631214\ttest: 26732.1228720\tbest: 26730.6606331 (1999)\ttotal: 10.9s\tremaining: 1m 37s\n",
      "3000:\tlearn: 7564.1300314\ttest: 26225.3412486\tbest: 26225.3412486 (3000)\ttotal: 16.1s\tremaining: 1m 31s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 26028.89296\n",
      "bestIteration = 3888\n",
      "\n",
      "Shrink model to first 3889 iterations.\n",
      "Learning rate set to 0.006969\n",
      "0:\tlearn: 52633.2252268\ttest: 50887.5091304\tbest: 50887.5091304 (0)\ttotal: 5.51ms\tremaining: 1m 50s\n",
      "1000:\tlearn: 16859.3856510\ttest: 26078.0065848\tbest: 26078.0065848 (1000)\ttotal: 5.76s\tremaining: 1m 49s\n",
      "2000:\tlearn: 11212.0636374\ttest: 24452.5223043\tbest: 24451.9512076 (1996)\ttotal: 11.1s\tremaining: 1m 39s\n",
      "3000:\tlearn: 7781.9881892\ttest: 23955.3433431\tbest: 23955.3433431 (3000)\ttotal: 16.8s\tremaining: 1m 35s\n",
      "4000:\tlearn: 5565.1688878\ttest: 23750.6306890\tbest: 23747.1788110 (3954)\ttotal: 22.7s\tremaining: 1m 30s\n",
      "5000:\tlearn: 3970.2831754\ttest: 23640.3871600\tbest: 23639.0549200 (4993)\ttotal: 28.7s\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 23637.19549\n",
      "bestIteration = 5078\n",
      "\n",
      "Shrink model to first 5079 iterations.\n",
      "Learning rate set to 0.007715\n",
      "0:\tlearn: 9422.9280959\ttest: 10890.9912853\tbest: 10890.9912853 (0)\ttotal: 5.75ms\tremaining: 1m 55s\n",
      "1000:\tlearn: 2204.5296047\ttest: 5556.6612092\tbest: 5556.4937301 (998)\ttotal: 5.87s\tremaining: 1m 51s\n",
      "2000:\tlearn: 1373.4837649\ttest: 5382.2866218\tbest: 5382.2866218 (2000)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "3000:\tlearn: 979.9577039\ttest: 5329.4071070\tbest: 5329.2371052 (2997)\ttotal: 16.9s\tremaining: 1m 35s\n",
      "4000:\tlearn: 730.1764346\ttest: 5303.2877651\tbest: 5303.2877651 (4000)\ttotal: 22.3s\tremaining: 1m 29s\n",
      "5000:\tlearn: 565.9664048\ttest: 5294.1325197\tbest: 5294.1325197 (5000)\ttotal: 27.9s\tremaining: 1m 23s\n",
      "6000:\tlearn: 446.5895010\ttest: 5288.1234953\tbest: 5288.0124043 (5914)\ttotal: 33.3s\tremaining: 1m 17s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 5288.012404\n",
      "bestIteration = 5914\n",
      "\n",
      "Shrink model to first 5915 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.007716\n",
      "0:\tlearn: 9962.5694678\ttest: 8731.2286523\tbest: 8731.2286523 (0)\ttotal: 5.19ms\tremaining: 1m 43s\n",
      "1000:\tlearn: 2133.1928860\ttest: 4595.5991221\tbest: 4595.5991221 (1000)\ttotal: 5.73s\tremaining: 1m 48s\n",
      "2000:\tlearn: 1369.9664860\ttest: 4411.0018127\tbest: 4411.0018127 (2000)\ttotal: 11.1s\tremaining: 1m 39s\n",
      "3000:\tlearn: 969.1378455\ttest: 4355.3102298\tbest: 4354.8391117 (2992)\ttotal: 16.8s\tremaining: 1m 35s\n",
      "4000:\tlearn: 722.1192871\ttest: 4334.1252893\tbest: 4333.9768134 (3983)\ttotal: 22.6s\tremaining: 1m 30s\n",
      "5000:\tlearn: 550.2900285\ttest: 4324.8895580\tbest: 4324.8448962 (4993)\ttotal: 28.4s\tremaining: 1m 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 4320.826708\n",
      "bestIteration = 5635\n",
      "\n",
      "Shrink model to first 5636 iterations.\n",
      "Learning rate set to 0.007716\n",
      "0:\tlearn: 10082.9302969\ttest: 8178.3960145\tbest: 8178.3960145 (0)\ttotal: 6.74ms\tremaining: 2m 14s\n",
      "1000:\tlearn: 2161.4914220\ttest: 3898.3859864\tbest: 3898.3859864 (1000)\ttotal: 5.87s\tremaining: 1m 51s\n",
      "2000:\tlearn: 1339.6922643\ttest: 3760.5665427\tbest: 3760.5665427 (2000)\ttotal: 11.6s\tremaining: 1m 44s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 3745.230861\n",
      "bestIteration = 2305\n",
      "\n",
      "Shrink model to first 2306 iterations.\n",
      "Learning rate set to 0.007716\n",
      "0:\tlearn: 9715.1887418\ttest: 9811.6638762\tbest: 9811.6638762 (0)\ttotal: 5.85ms\tremaining: 1m 57s\n",
      "1000:\tlearn: 2317.5052627\ttest: 5506.0279286\tbest: 5506.0279286 (1000)\ttotal: 6.06s\tremaining: 1m 54s\n",
      "2000:\tlearn: 1448.9249269\ttest: 5257.1829448\tbest: 5257.1641794 (1999)\ttotal: 11.7s\tremaining: 1m 44s\n",
      "3000:\tlearn: 1033.4806339\ttest: 5196.3762060\tbest: 5196.1042207 (2997)\ttotal: 17.3s\tremaining: 1m 37s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 5186.221969\n",
      "bestIteration = 3454\n",
      "\n",
      "Shrink model to first 3455 iterations.\n",
      "Learning rate set to 0.007716\n",
      "0:\tlearn: 9446.8274319\ttest: 10794.5653566\tbest: 10794.5653566 (0)\ttotal: 5.76ms\tremaining: 1m 55s\n",
      "1000:\tlearn: 2119.6725586\ttest: 5739.3535209\tbest: 5739.3535209 (1000)\ttotal: 5.76s\tremaining: 1m 49s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 5634.943436\n",
      "bestIteration = 1631\n",
      "\n",
      "Shrink model to first 1632 iterations.\n"
     ]
    }
   ],
   "source": [
    "# 타자데이터 도출\n",
    "hitter_performance = pd.concat([rf_model2(X1, y1, X2, y2),\n",
    "                                  lgbm_model2(X1, y1, X2, y2),\n",
    "                                  xgb_model2(X1, y1, X2, y2),\n",
    "                                  cb_model2(X1, y1, X2, y2),\n",
    "                                  knn_model2(X1, y1, X2, y2),\n",
    "                                  regression_model2(X1, y1, X2, y2)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 투수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분할\n",
    "col_dict, X1, y1, X2, y2 = Xy_split2(pitcher_fa, pitcher_nonfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's rmse: 27140.7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's rmse: 22597.6\n",
      "Early stopping, best iteration is:\n",
      "[1807]\tvalid_0's rmse: 22595.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[441]\tvalid_0's rmse: 22253.3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[282]\tvalid_0's rmse: 22813.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[438]\tvalid_0's rmse: 19944.1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's rmse: 5071.22\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[1000]\tvalid_0's rmse: 10165.2\n",
      "Early stopping, best iteration is:\n",
      "[1476]\tvalid_0's rmse: 10155.2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 5137.99\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's rmse: 5466.63\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's rmse: 6777.25\n",
      "[0]\ttrain-rmse:42096.71094\teval-rmse:55403.33203\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-rmse:6753.90723\teval-rmse:28865.72070\n",
      "\n",
      "[0]\ttrain-rmse:43922.57812\teval-rmse:47696.77734\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[5]\ttrain-rmse:11261.45312\teval-rmse:37115.14844\n",
      "\n",
      "[0]\ttrain-rmse:45474.20312\teval-rmse:38902.83594\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-rmse:903.23560\teval-rmse:28192.84961\n",
      "\n",
      "[0]\ttrain-rmse:42044.28516\teval-rmse:51176.19141\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[28]\ttrain-rmse:493.47415\teval-rmse:23753.78320\n",
      "\n",
      "[0]\ttrain-rmse:44368.84375\teval-rmse:42576.67969\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[129]\ttrain-rmse:0.59957\teval-rmse:19020.18945\n",
      "\n",
      "[0]\ttrain-rmse:10597.85840\teval-rmse:8390.29297\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[91]\ttrain-rmse:139.48233\teval-rmse:4624.49072\n",
      "\n",
      "[0]\ttrain-rmse:9357.32227\teval-rmse:14663.26953\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-rmse:2721.43506\teval-rmse:11397.61133\n",
      "\n",
      "[0]\ttrain-rmse:10456.18262\teval-rmse:9354.75684\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[126]\ttrain-rmse:43.39521\teval-rmse:4653.41895\n",
      "\n",
      "[0]\ttrain-rmse:10432.17871\teval-rmse:9753.20215\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[35]\ttrain-rmse:994.18060\teval-rmse:4859.75977\n",
      "\n",
      "[0]\ttrain-rmse:10134.14648\teval-rmse:11022.16699\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[37]\ttrain-rmse:796.49744\teval-rmse:6698.02393\n",
      "\n",
      "Learning rate set to 0.006132\n",
      "0:\tlearn: 45097.5759945\ttest: 55463.2737392\tbest: 55463.2737392 (0)\ttotal: 5.54ms\tremaining: 1m 50s\n",
      "1000:\tlearn: 12358.7735949\ttest: 28506.0672759\tbest: 28502.7582528 (999)\ttotal: 4.62s\tremaining: 1m 27s\n",
      "2000:\tlearn: 7208.4430749\ttest: 27777.8412633\tbest: 27776.8932220 (1931)\ttotal: 10s\tremaining: 1m 30s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 27769.95788\n",
      "bestIteration = 2010\n",
      "\n",
      "Shrink model to first 2011 iterations.\n",
      "Learning rate set to 0.006132\n",
      "0:\tlearn: 47955.8103779\ttest: 44699.5509085\tbest: 44699.5509085 (0)\ttotal: 4.63ms\tremaining: 1m 32s\n",
      "1000:\tlearn: 12567.6998208\ttest: 24118.0533635\tbest: 24118.0533635 (1000)\ttotal: 4.66s\tremaining: 1m 28s\n",
      "2000:\tlearn: 7278.9894341\ttest: 23084.0078632\tbest: 23083.4632240 (1999)\ttotal: 8.9s\tremaining: 1m 20s\n",
      "3000:\tlearn: 4388.1207598\ttest: 22537.8676037\tbest: 22537.7456483 (2997)\ttotal: 13.5s\tremaining: 1m 16s\n",
      "4000:\tlearn: 2715.2338977\ttest: 22375.4093926\tbest: 22375.4093926 (4000)\ttotal: 18s\tremaining: 1m 12s\n",
      "5000:\tlearn: 1834.7105157\ttest: 22309.5447946\tbest: 22306.5382845 (4972)\ttotal: 22.5s\tremaining: 1m 7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22306.53828\n",
      "bestIteration = 4972\n",
      "\n",
      "Shrink model to first 4973 iterations.\n",
      "Learning rate set to 0.006132\n",
      "0:\tlearn: 49487.6940406\ttest: 37595.8143651\tbest: 37595.8143651 (0)\ttotal: 4.5ms\tremaining: 1m 29s\n",
      "1000:\tlearn: 12918.1115094\ttest: 23668.0646954\tbest: 23667.3322980 (999)\ttotal: 5.09s\tremaining: 1m 36s\n",
      "2000:\tlearn: 7402.4574723\ttest: 22545.9996843\tbest: 22545.9996843 (2000)\ttotal: 10.1s\tremaining: 1m 31s\n",
      "3000:\tlearn: 4316.2869300\ttest: 22012.0062085\tbest: 22012.0062085 (3000)\ttotal: 15.2s\tremaining: 1m 26s\n",
      "4000:\tlearn: 2665.3242997\ttest: 21795.6481151\tbest: 21795.6481151 (4000)\ttotal: 19.8s\tremaining: 1m 19s\n",
      "5000:\tlearn: 1723.5985508\ttest: 21693.9963857\tbest: 21693.9963857 (5000)\ttotal: 24.2s\tremaining: 1m 12s\n",
      "6000:\tlearn: 1148.1977499\ttest: 21643.7229646\tbest: 21643.5402433 (5988)\ttotal: 28.5s\tremaining: 1m 6s\n",
      "7000:\tlearn: 774.5556358\ttest: 21614.5747336\tbest: 21614.1259901 (6988)\ttotal: 32.9s\tremaining: 1m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 21608.05461\n",
      "bestIteration = 7285\n",
      "\n",
      "Shrink model to first 7286 iterations.\n",
      "Learning rate set to 0.006132\n",
      "0:\tlearn: 45702.4273809\ttest: 53401.6677940\tbest: 53401.6677940 (0)\ttotal: 4.18ms\tremaining: 1m 23s\n",
      "1000:\tlearn: 12826.5327345\ttest: 23738.9119265\tbest: 23738.9119265 (1000)\ttotal: 4.47s\tremaining: 1m 24s\n",
      "2000:\tlearn: 6809.6853900\ttest: 22407.4591364\tbest: 22407.4591364 (2000)\ttotal: 8.66s\tremaining: 1m 17s\n",
      "3000:\tlearn: 3876.9698052\ttest: 22230.4730658\tbest: 22230.4730658 (3000)\ttotal: 12.9s\tremaining: 1m 13s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 22219.15582\n",
      "bestIteration = 3144\n",
      "\n",
      "Shrink model to first 3145 iterations.\n",
      "Learning rate set to 0.006134\n",
      "0:\tlearn: 48158.2443486\ttest: 43814.9228789\tbest: 43814.9228789 (0)\ttotal: 4.48ms\tremaining: 1m 29s\n",
      "1000:\tlearn: 13271.5420450\ttest: 21981.7808415\tbest: 21981.2369748 (999)\ttotal: 4.51s\tremaining: 1m 25s\n",
      "2000:\tlearn: 7738.4593138\ttest: 21053.1879651\tbest: 21049.6722897 (1968)\ttotal: 8.85s\tremaining: 1m 19s\n",
      "3000:\tlearn: 4498.6181139\ttest: 20723.6269209\tbest: 20723.6269209 (3000)\ttotal: 13.2s\tremaining: 1m 14s\n",
      "4000:\tlearn: 2735.8997720\ttest: 20612.4324630\tbest: 20609.7396098 (3963)\ttotal: 17.8s\tremaining: 1m 11s\n",
      "5000:\tlearn: 1764.2847609\ttest: 20563.9755432\tbest: 20562.7114201 (4986)\ttotal: 22.2s\tremaining: 1m 6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 20548.18065\n",
      "bestIteration = 5431\n",
      "\n",
      "Shrink model to first 5432 iterations.\n",
      "Learning rate set to 0.007613\n",
      "0:\tlearn: 10816.4610887\ttest: 7667.1277881\tbest: 7667.1277881 (0)\ttotal: 5.88ms\tremaining: 1m 57s\n",
      "1000:\tlearn: 3392.7860342\ttest: 4599.1500301\tbest: 4599.1500301 (1000)\ttotal: 5.74s\tremaining: 1m 48s\n",
      "2000:\tlearn: 2210.9592662\ttest: 4464.1187862\tbest: 4464.1143063 (1998)\ttotal: 11.2s\tremaining: 1m 40s\n",
      "3000:\tlearn: 1548.5139638\ttest: 4365.6726161\tbest: 4364.8339618 (2993)\ttotal: 16.7s\tremaining: 1m 34s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 4352.566872\n",
      "bestIteration = 3339\n",
      "\n",
      "Shrink model to first 3340 iterations.\n",
      "Learning rate set to 0.007613\n",
      "0:\tlearn: 9100.1320809\ttest: 13987.4398271\tbest: 13987.4398271 (0)\ttotal: 5.91ms\tremaining: 1m 58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:\tlearn: 3590.8933266\ttest: 10958.8817143\tbest: 10958.8817143 (1000)\ttotal: 5.51s\tremaining: 1m 44s\n",
      "2000:\tlearn: 2291.7391210\ttest: 10537.0313822\tbest: 10536.8762805 (1999)\ttotal: 11.2s\tremaining: 1m 41s\n",
      "3000:\tlearn: 1623.2229411\ttest: 10461.8522457\tbest: 10461.7201636 (2993)\ttotal: 17.1s\tremaining: 1m 36s\n",
      "4000:\tlearn: 1198.2722074\ttest: 10416.2499857\tbest: 10416.2499857 (4000)\ttotal: 22.9s\tremaining: 1m 31s\n",
      "5000:\tlearn: 889.0198635\ttest: 10394.0144227\tbest: 10393.5625432 (4945)\ttotal: 28.5s\tremaining: 1m 25s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 10392.87111\n",
      "bestIteration = 5043\n",
      "\n",
      "Shrink model to first 5044 iterations.\n",
      "Learning rate set to 0.007614\n",
      "0:\tlearn: 10749.3147426\ttest: 8022.8783040\tbest: 8022.8783040 (0)\ttotal: 6.87ms\tremaining: 2m 17s\n",
      "1000:\tlearn: 3405.8282848\ttest: 4796.2683041\tbest: 4796.2062182 (996)\ttotal: 5.42s\tremaining: 1m 42s\n",
      "2000:\tlearn: 2155.4990993\ttest: 4564.8534521\tbest: 4564.8534521 (2000)\ttotal: 10.4s\tremaining: 1m 33s\n",
      "3000:\tlearn: 1500.4618139\ttest: 4476.1270863\tbest: 4475.3087320 (2985)\ttotal: 15.5s\tremaining: 1m 28s\n",
      "4000:\tlearn: 1093.0056625\ttest: 4432.5493811\tbest: 4432.5493811 (4000)\ttotal: 20.9s\tremaining: 1m 23s\n",
      "5000:\tlearn: 824.9839401\ttest: 4412.6001542\tbest: 4412.2437502 (4958)\ttotal: 26.3s\tremaining: 1m 18s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 4402.021372\n",
      "bestIteration = 5680\n",
      "\n",
      "Shrink model to first 5681 iterations.\n",
      "Learning rate set to 0.007614\n",
      "0:\tlearn: 10469.7732805\ttest: 9382.2869505\tbest: 9382.2869505 (0)\ttotal: 6.03ms\tremaining: 2m\n",
      "1000:\tlearn: 3342.8202061\ttest: 5348.2718131\tbest: 5348.2718131 (1000)\ttotal: 6.46s\tremaining: 2m 2s\n",
      "2000:\tlearn: 2183.0024859\ttest: 5044.0434831\tbest: 5044.0434831 (2000)\ttotal: 12.4s\tremaining: 1m 51s\n",
      "3000:\tlearn: 1548.0646144\ttest: 4933.5976494\tbest: 4933.5976494 (3000)\ttotal: 18.3s\tremaining: 1m 43s\n",
      "4000:\tlearn: 1092.8715676\ttest: 4890.7939467\tbest: 4890.1763925 (3926)\ttotal: 24s\tremaining: 1m 35s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 4884.971244\n",
      "bestIteration = 4229\n",
      "\n",
      "Shrink model to first 4230 iterations.\n",
      "Learning rate set to 0.007614\n",
      "0:\tlearn: 10070.7703382\ttest: 10993.8054941\tbest: 10993.8054941 (0)\ttotal: 5.07ms\tremaining: 1m 41s\n",
      "1000:\tlearn: 3499.6544898\ttest: 6885.6990345\tbest: 6885.6990345 (1000)\ttotal: 5.36s\tremaining: 1m 41s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 6704.526078\n",
      "bestIteration = 1622\n",
      "\n",
      "Shrink model to first 1623 iterations.\n"
     ]
    }
   ],
   "source": [
    "# 타자데이터 도출\n",
    "pitcher_performance = pd.concat([rf_model2(X1, y1, X2, y2),\n",
    "                                  lgbm_model2(X1, y1, X2, y2),\n",
    "                                  xgb_model2(X1, y1, X2, y2),\n",
    "                                  cb_model2(X1, y1, X2, y2),\n",
    "                                  knn_model2(X1, y1, X2, y2),\n",
    "                                  regression_model2(X1, y1, X2, y2)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>knn</th>\n",
       "      <th>regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>17756.511877</td>\n",
       "      <td>17344.780459</td>\n",
       "      <td>17615.850723</td>\n",
       "      <td>16803.113841</td>\n",
       "      <td>24883.364546</td>\n",
       "      <td>20083.710893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>14739.023109</td>\n",
       "      <td>14084.926387</td>\n",
       "      <td>16057.724276</td>\n",
       "      <td>14045.360562</td>\n",
       "      <td>20386.988808</td>\n",
       "      <td>20107.498774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>13968.258519</td>\n",
       "      <td>14239.525544</td>\n",
       "      <td>17409.261194</td>\n",
       "      <td>14004.013357</td>\n",
       "      <td>25941.790938</td>\n",
       "      <td>20096.240100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>19168.326139</td>\n",
       "      <td>17928.614851</td>\n",
       "      <td>20482.298400</td>\n",
       "      <td>16334.671917</td>\n",
       "      <td>25543.224658</td>\n",
       "      <td>22059.259482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv5</th>\n",
       "      <td>16411.554127</td>\n",
       "      <td>17348.643264</td>\n",
       "      <td>15849.512035</td>\n",
       "      <td>15017.596038</td>\n",
       "      <td>23176.984634</td>\n",
       "      <td>19163.790041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균</th>\n",
       "      <td>16408.734754</td>\n",
       "      <td>16189.298101</td>\n",
       "      <td>17482.929326</td>\n",
       "      <td>15240.951143</td>\n",
       "      <td>23986.470717</td>\n",
       "      <td>20302.099858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rf          lgbm           xgb            cb           knn  \\\n",
       "cv1  17756.511877  17344.780459  17615.850723  16803.113841  24883.364546   \n",
       "cv2  14739.023109  14084.926387  16057.724276  14045.360562  20386.988808   \n",
       "cv3  13968.258519  14239.525544  17409.261194  14004.013357  25941.790938   \n",
       "cv4  19168.326139  17928.614851  20482.298400  16334.671917  25543.224658   \n",
       "cv5  16411.554127  17348.643264  15849.512035  15017.596038  23176.984634   \n",
       "평균   16408.734754  16189.298101  17482.929326  15240.951143  23986.470717   \n",
       "\n",
       "       regression  \n",
       "cv1  20083.710893  \n",
       "cv2  20107.498774  \n",
       "cv3  20096.240100  \n",
       "cv4  22059.259482  \n",
       "cv5  19163.790041  \n",
       "평균   20302.099858  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitter_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>knn</th>\n",
       "      <th>regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>14278.349071</td>\n",
       "      <td>14048.687759</td>\n",
       "      <td>14932.137469</td>\n",
       "      <td>14162.344062</td>\n",
       "      <td>17663.649946</td>\n",
       "      <td>19593.674820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>17679.692605</td>\n",
       "      <td>14195.185456</td>\n",
       "      <td>20991.016021</td>\n",
       "      <td>14215.293980</td>\n",
       "      <td>21348.173849</td>\n",
       "      <td>19977.069332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>14805.813316</td>\n",
       "      <td>11825.288097</td>\n",
       "      <td>14478.598724</td>\n",
       "      <td>11298.968623</td>\n",
       "      <td>14078.143041</td>\n",
       "      <td>16096.854689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>12523.484782</td>\n",
       "      <td>12189.648393</td>\n",
       "      <td>12442.969417</td>\n",
       "      <td>11728.052739</td>\n",
       "      <td>16100.025268</td>\n",
       "      <td>18404.907935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv5</th>\n",
       "      <td>11609.102568</td>\n",
       "      <td>11423.317050</td>\n",
       "      <td>11023.186980</td>\n",
       "      <td>11645.887732</td>\n",
       "      <td>15818.664859</td>\n",
       "      <td>19446.543509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균</th>\n",
       "      <td>14179.288468</td>\n",
       "      <td>12736.425351</td>\n",
       "      <td>14773.581723</td>\n",
       "      <td>12610.109427</td>\n",
       "      <td>17001.731393</td>\n",
       "      <td>18703.810057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rf          lgbm           xgb            cb           knn  \\\n",
       "cv1  14278.349071  14048.687759  14932.137469  14162.344062  17663.649946   \n",
       "cv2  17679.692605  14195.185456  20991.016021  14215.293980  21348.173849   \n",
       "cv3  14805.813316  11825.288097  14478.598724  11298.968623  14078.143041   \n",
       "cv4  12523.484782  12189.648393  12442.969417  11728.052739  16100.025268   \n",
       "cv5  11609.102568  11423.317050  11023.186980  11645.887732  15818.664859   \n",
       "평균   14179.288468  12736.425351  14773.581723  12610.109427  17001.731393   \n",
       "\n",
       "       regression  \n",
       "cv1  19593.674820  \n",
       "cv2  19977.069332  \n",
       "cv3  16096.854689  \n",
       "cv4  18404.907935  \n",
       "cv5  19446.543509  \n",
       "평균   18703.810057  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitcher_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
