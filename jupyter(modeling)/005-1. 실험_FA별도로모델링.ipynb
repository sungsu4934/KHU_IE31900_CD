{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 패키지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의\n",
    " 1. Random Forest\n",
    " 2. Lightgbm\n",
    " 3. Xgboost\n",
    " 4. Catboost\n",
    " 5. Knn\n",
    " 6. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_split2(dataset1, dataset2):\n",
    "    \n",
    "    X1 = dataset1.drop('연봉', axis=1)\n",
    "    column_dict = {f'variable{idx+1}':col for idx, col in enumerate(X1.columns)}\n",
    "    X1 = X1.rename(columns = {col:f'variable{idx+1}' for idx, col in enumerate(X1.columns)})\n",
    "    y1 = dataset1['연봉']\n",
    "    \n",
    "    X2 = dataset2.drop('연봉', axis=1)\n",
    "    X2 = X2.rename(columns = {col:f'variable{idx+1}' for idx, col in enumerate(X2.columns)})\n",
    "    y2 = dataset2['연봉']\n",
    "    \n",
    "    return column_dict, X1, y1, X2, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # rf 모델링\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        rf_model = RandomForestRegressor(random_state = 42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(rf_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        rf_model = RandomForestRegressor(random_state = 42)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(rf_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # rf 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'rf':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # lgbm 모델링\n",
    "    lgb_params = {\"objective\" : \"rmse\",\n",
    "                 \"verbosity\" : -1}\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    \n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :].values\n",
    "        y_train = data_y1[tr_idx].values\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :].values\n",
    "        y_valid = data_y1[val_idx].values\n",
    "\n",
    "        lgb_dtrain = lgb.Dataset(data = X_train, label = y_train) \n",
    "        lgb_dvalid = lgb.Dataset(data = X_valid, label = y_valid) \n",
    "\n",
    "        lgb_model = lgb.train(lgb_params, lgb_dtrain, 20000, valid_sets=[lgb_dvalid], early_stopping_rounds=100, verbose_eval=1000)\n",
    "        \n",
    "        pred_valid = list(lgb_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :].values\n",
    "        y_train = data_y2[tr_idx].values\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :].values\n",
    "        y_valid = data_y2[val_idx].values\n",
    "\n",
    "        lgb_dtrain = lgb.Dataset(data = X_train, label = y_train) \n",
    "        lgb_dvalid = lgb.Dataset(data = X_valid, label = y_valid) \n",
    "\n",
    "        lgb_model = lgb.train(lgb_params, lgb_dtrain, 20000, valid_sets=[lgb_dvalid], early_stopping_rounds=100, verbose_eval=1000)\n",
    "        \n",
    "        pred_valid = list(lgb_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "\n",
    "    # lgbm 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'lgbm':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "    \n",
    "    # xgb 모델링\n",
    "    xgb_final_param = {\n",
    "          \"objective\" : 'reg:squarederror',\n",
    "          \"random_state\" : 42,\n",
    "          \"verbosity\" : 0\n",
    "          }\n",
    "    \n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :].values\n",
    "        y_train = data_y1[tr_idx].values\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :].values\n",
    "        y_valid = data_y1[val_idx].values\n",
    "\n",
    "        xgb_dtrain = xgb.DMatrix(data = X_train, label = y_train) \n",
    "        xgb_dvalid = xgb.DMatrix(data = X_valid, label = y_valid) \n",
    "\n",
    "        xgb_model = xgb.train(params = xgb_final_param, dtrain = xgb_dtrain, num_boost_round = 20000, early_stopping_rounds = 100, verbose_eval = 1000, evals=[(xgb_dtrain, 'train'), (xgb_dvalid,'eval')])\n",
    "\n",
    "        pred_valid = list(xgb_model.predict(xgb.DMatrix(data = X_valid)))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :].values\n",
    "        y_train = data_y2[tr_idx].values\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :].values\n",
    "        y_valid = data_y2[val_idx].values\n",
    "\n",
    "        xgb_dtrain = xgb.DMatrix(data = X_train, label = y_train) \n",
    "        xgb_dvalid = xgb.DMatrix(data = X_valid, label = y_valid) \n",
    "\n",
    "        xgb_model = xgb.train(params = xgb_final_param, dtrain = xgb_dtrain, num_boost_round = 20000, early_stopping_rounds = 100, verbose_eval = 1000, evals=[(xgb_dtrain, 'train'), (xgb_dvalid,'eval')])\n",
    "\n",
    "        pred_valid = list(xgb_model.predict(xgb.DMatrix(data = X_valid)))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # xgb 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'xgb':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cb_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # cb 모델링\n",
    "    cat_cols = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        cb_dtrain = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "        cb_dvalid = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "        cb_model = CatBoostRegressor(iterations=20000, eval_metric='RMSE', loss_function='RMSE', verbose = 0)\n",
    "        cb_model.fit(cb_dtrain, eval_set=cb_dvalid, early_stopping_rounds=100, verbose_eval=1000, use_best_model=True)\n",
    "\n",
    "        pred_valid = list(cb_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        cb_dtrain = Pool(data=X_train, label=y_train, cat_features=cat_cols)\n",
    "        cb_dvalid = Pool(data=X_valid, label=y_valid, cat_features=cat_cols)\n",
    "\n",
    "        cb_model = CatBoostRegressor(iterations=20000, eval_metric='RMSE', loss_function='RMSE', verbose = 0)\n",
    "        cb_model.fit(cb_dtrain, eval_set=cb_dvalid, early_stopping_rounds=100, verbose_eval=1000, use_best_model=True)\n",
    "        \n",
    "        pred_valid = list(cb_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # cb 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "    \n",
    "    output = pd.DataFrame({'cb':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # knn 모델링\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        knn_model = KNeighborsRegressor()\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(knn_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        knn_model = KNeighborsRegressor()\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(knn_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # knn 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'knn':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model2(data_x1, data_y1, data_x2, data_y2):\n",
    "\n",
    "    # knn 모델링\n",
    "    label_list = []\n",
    "    pred_list = []\n",
    "    cv = KFold(n_splits = n_splits, shuffle = True, random_state=42)\n",
    "\n",
    "    for tr_idx, val_idx in cv.split(data_x1):  \n",
    "\n",
    "        X_train = data_x1.iloc[tr_idx, :]\n",
    "        y_train = data_y1[tr_idx]\n",
    "\n",
    "        X_valid = data_x1.iloc[val_idx, :]\n",
    "        y_valid = data_y1[val_idx]\n",
    "\n",
    "        regression_model = LinearRegression()\n",
    "        regression_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(regression_model.predict(X_valid))\n",
    "        pred_list.append(pred_valid)\n",
    "        label_list.append(list(y_valid))\n",
    "        \n",
    "        \n",
    "    for idx, (tr_idx, val_idx) in enumerate(cv.split(data_x2)):  \n",
    "\n",
    "        X_train = data_x2.iloc[tr_idx, :]\n",
    "        y_train = data_y2[tr_idx]\n",
    "\n",
    "        X_valid = data_x2.iloc[val_idx, :]\n",
    "        y_valid = data_y2[val_idx]\n",
    "\n",
    "        regression_model = LinearRegression()\n",
    "        regression_model.fit(X_train, y_train)\n",
    "\n",
    "        pred_valid = list(regression_model.predict(X_valid))\n",
    "        pred_list[idx].extend(pred_valid)\n",
    "        label_list[idx].extend(list(y_valid))\n",
    "        \n",
    "    # knn 성능종합\n",
    "    performance = [mean_squared_error(label_list[num], pred_list[num], squared=False) for num in range(5)]\n",
    "    performance.append(np.mean(performance))\n",
    "\n",
    "    output = pd.DataFrame({'regression':performance}, index=['cv1','cv2','cv3','cv4','cv5','평균'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test분할 후 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitter_fa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver1/타자_fa(모델링용).csv')\n",
    "hitter_nonfa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver1/타자_nonfa(모델링용).csv')\n",
    "pitcher_fa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver1/투수_fa(모델링용).csv')\n",
    "pitcher_nonfa = pd.read_csv('../선수데이터(전처리완료)/모델링용ver1/투수_nonfa(모델링용).csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 타자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분할\n",
    "col_dict, X1, y1, X2, y2 = Xy_split2(hitter_fa, hitter_nonfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's rmse: 37369.6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's rmse: 33883.7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's rmse: 52365\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's rmse: 29719.5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's rmse: 41615.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's rmse: 14422.7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's rmse: 12996.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's rmse: 13866.8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's rmse: 8994.76\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's rmse: 11573\n",
      "[0]\ttrain-rmse:77754.78125\teval-rmse:67701.38281\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[5]\ttrain-rmse:21034.82617\teval-rmse:45257.90625\n",
      "\n",
      "[0]\ttrain-rmse:76824.75781\teval-rmse:76183.67188\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[34]\ttrain-rmse:215.37126\teval-rmse:42994.29688\n",
      "\n",
      "[0]\ttrain-rmse:71437.32031\teval-rmse:96814.89844\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[17]\ttrain-rmse:1937.54370\teval-rmse:57684.91406\n",
      "\n",
      "[0]\ttrain-rmse:76157.11719\teval-rmse:78350.57031\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[35]\ttrain-rmse:202.43494\teval-rmse:34533.61719\n",
      "\n",
      "[0]\ttrain-rmse:75684.98438\teval-rmse:77505.39062\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[10]\ttrain-rmse:7894.31494\teval-rmse:29620.63867\n",
      "\n",
      "[0]\ttrain-rmse:22806.61133\teval-rmse:28694.86719\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[40]\ttrain-rmse:1625.46130\teval-rmse:14745.58398\n",
      "\n",
      "[0]\ttrain-rmse:23262.30859\teval-rmse:26207.56641\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-rmse:175.10759\teval-rmse:11639.64160\n",
      "\n",
      "[0]\ttrain-rmse:23547.54688\teval-rmse:24186.86719\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-rmse:4171.89746\teval-rmse:13014.34473\n",
      "\n",
      "[0]\ttrain-rmse:24822.31641\teval-rmse:19317.91797\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[23]\ttrain-rmse:2494.72412\teval-rmse:8746.42871\n",
      "\n",
      "[0]\ttrain-rmse:23966.61328\teval-rmse:23685.84180\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[69]\ttrain-rmse:724.14490\teval-rmse:11764.77344\n",
      "\n",
      "Learning rate set to 0.004782\n",
      "0:\tlearn: 67808.7195813\ttest: 43799.6967701\tbest: 43799.6967701 (0)\ttotal: 136ms\tremaining: 45m 23s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 32627.13933\n",
      "bestIteration = 471\n",
      "\n",
      "Shrink model to first 472 iterations.\n",
      "Learning rate set to 0.004782\n",
      "0:\tlearn: 66953.6796980\ttest: 48925.2253100\tbest: 48925.2253100 (0)\ttotal: 3.1ms\tremaining: 1m 1s\n",
      "1000:\tlearn: 19884.3034309\ttest: 38095.4202319\tbest: 38078.7018017 (995)\ttotal: 2.2s\tremaining: 41.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 37862.20359\n",
      "bestIteration = 1243\n",
      "\n",
      "Shrink model to first 1244 iterations.\n",
      "Learning rate set to 0.004789\n",
      "0:\tlearn: 57948.9555748\ttest: 83273.4766468\tbest: 83273.4766468 (0)\ttotal: 2.78ms\tremaining: 55.6s\n",
      "1000:\tlearn: 18586.0224430\ttest: 56170.6688017\tbest: 56170.6688017 (1000)\ttotal: 2.37s\tremaining: 44.9s\n",
      "2000:\tlearn: 7057.2611697\ttest: 53886.3445691\tbest: 53885.8612320 (1999)\ttotal: 4.48s\tremaining: 40.3s\n",
      "3000:\tlearn: 2614.5156105\ttest: 53301.8597116\tbest: 53300.9713770 (2999)\ttotal: 6.6s\tremaining: 37.4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 53262.1856\n",
      "bestIteration = 3348\n",
      "\n",
      "Shrink model to first 3349 iterations.\n",
      "Learning rate set to 0.004789\n",
      "0:\tlearn: 62869.9371590\ttest: 66884.4122397\tbest: 66884.4122397 (0)\ttotal: 4.6ms\tremaining: 1m 31s\n",
      "1000:\tlearn: 21598.4847073\ttest: 37263.8336493\tbest: 37263.8336493 (1000)\ttotal: 2.44s\tremaining: 46.3s\n",
      "2000:\tlearn: 9376.0702804\ttest: 33546.1620474\tbest: 33541.1383536 (1997)\ttotal: 4.63s\tremaining: 41.6s\n",
      "3000:\tlearn: 4130.1598006\ttest: 32801.0672501\tbest: 32800.6427485 (2997)\ttotal: 6.86s\tremaining: 38.8s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 32629.73286\n",
      "bestIteration = 3805\n",
      "\n",
      "Shrink model to first 3806 iterations.\n",
      "Learning rate set to 0.004789\n",
      "0:\tlearn: 62274.8774469\ttest: 69181.2472728\tbest: 69181.2472728 (0)\ttotal: 2.46ms\tremaining: 49.3s\n",
      "1000:\tlearn: 21625.3382176\ttest: 40531.6161930\tbest: 40531.6161930 (1000)\ttotal: 2.39s\tremaining: 45.4s\n",
      "2000:\tlearn: 9286.7026451\ttest: 37098.4466596\tbest: 37098.4466596 (2000)\ttotal: 4.58s\tremaining: 41.2s\n",
      "3000:\tlearn: 3796.7485437\ttest: 36329.8805979\tbest: 36327.9213601 (2994)\ttotal: 6.77s\tremaining: 38.4s\n",
      "4000:\tlearn: 1668.0683982\ttest: 36194.9726552\tbest: 36194.9202480 (3999)\ttotal: 9.01s\tremaining: 36s\n",
      "5000:\tlearn: 762.8872807\ttest: 36124.3710345\tbest: 36124.0761894 (4994)\ttotal: 11.2s\tremaining: 33.7s\n",
      "6000:\tlearn: 341.9497681\ttest: 36097.5944692\tbest: 36097.4459756 (5998)\ttotal: 13.5s\tremaining: 31.5s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 36096.65423\n",
      "bestIteration = 6032\n",
      "\n",
      "Shrink model to first 6033 iterations.\n",
      "Learning rate set to 0.008879\n",
      "0:\tlearn: 27451.3124571\ttest: 32891.1793901\tbest: 32891.1793901 (0)\ttotal: 5.46ms\tremaining: 1m 49s\n",
      "1000:\tlearn: 6820.5420923\ttest: 14452.5562643\tbest: 14452.5562643 (1000)\ttotal: 5.82s\tremaining: 1m 50s\n",
      "2000:\tlearn: 4405.8338434\ttest: 13682.3785850\tbest: 13682.2605441 (1993)\ttotal: 11.5s\tremaining: 1m 43s\n",
      "3000:\tlearn: 3155.9157622\ttest: 13403.0546073\tbest: 13403.0546073 (3000)\ttotal: 17.2s\tremaining: 1m 37s\n",
      "4000:\tlearn: 2434.9490865\ttest: 13280.5319845\tbest: 13280.5319845 (4000)\ttotal: 23.1s\tremaining: 1m 32s\n",
      "5000:\tlearn: 1917.2150552\ttest: 13224.0254584\tbest: 13223.5425157 (4995)\ttotal: 28.9s\tremaining: 1m 26s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 13207.92097\n",
      "bestIteration = 5524\n",
      "\n",
      "Shrink model to first 5525 iterations.\n",
      "Learning rate set to 0.008879\n",
      "0:\tlearn: 28085.2286209\ttest: 30655.8919764\tbest: 30655.8919764 (0)\ttotal: 5.78ms\tremaining: 1m 55s\n",
      "1000:\tlearn: 7355.3414514\ttest: 12457.0074268\tbest: 12457.0074268 (1000)\ttotal: 6.17s\tremaining: 1m 57s\n",
      "2000:\tlearn: 4801.4458413\ttest: 11887.1560334\tbest: 11887.0522981 (1989)\ttotal: 12.1s\tremaining: 1m 48s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 11707.2451\n",
      "bestIteration = 2636\n",
      "\n",
      "Shrink model to first 2637 iterations.\n",
      "Learning rate set to 0.008879\n",
      "0:\tlearn: 28579.9223818\ttest: 28712.8594066\tbest: 28712.8594066 (0)\ttotal: 6.4ms\tremaining: 2m 7s\n",
      "1000:\tlearn: 6514.5380162\ttest: 13520.4282668\tbest: 13520.3333869 (999)\ttotal: 6.42s\tremaining: 2m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 13242.47999\n",
      "bestIteration = 1861\n",
      "\n",
      "Shrink model to first 1862 iterations.\n",
      "Learning rate set to 0.00888\n",
      "0:\tlearn: 30018.7861485\ttest: 22083.4405060\tbest: 22083.4405060 (0)\ttotal: 6.14ms\tremaining: 2m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:\tlearn: 7387.2848838\ttest: 8751.8301171\tbest: 8751.8301171 (1000)\ttotal: 6.58s\tremaining: 2m 4s\n",
      "2000:\tlearn: 4864.4274611\ttest: 8202.9999715\tbest: 8202.9999715 (2000)\ttotal: 13.1s\tremaining: 1m 58s\n",
      "3000:\tlearn: 3427.2369209\ttest: 7992.9899190\tbest: 7990.9397175 (2989)\ttotal: 21.3s\tremaining: 2m\n",
      "4000:\tlearn: 2546.2230469\ttest: 7878.7084388\tbest: 7878.6857296 (3999)\ttotal: 29.9s\tremaining: 1m 59s\n",
      "5000:\tlearn: 1978.3562898\ttest: 7800.7860999\tbest: 7800.6288480 (4998)\ttotal: 38.5s\tremaining: 1m 55s\n",
      "6000:\tlearn: 1589.1952506\ttest: 7751.0242247\tbest: 7751.0242247 (6000)\ttotal: 45.9s\tremaining: 1m 47s\n",
      "7000:\tlearn: 1330.2612901\ttest: 7720.9534036\tbest: 7720.6580019 (6993)\ttotal: 52.6s\tremaining: 1m 37s\n",
      "8000:\tlearn: 1094.2133393\ttest: 7696.9941805\tbest: 7696.9941805 (8000)\ttotal: 59.5s\tremaining: 1m 29s\n",
      "9000:\tlearn: 915.3022894\ttest: 7687.2975921\tbest: 7687.2975921 (9000)\ttotal: 1m 5s\tremaining: 1m 20s\n",
      "10000:\tlearn: 771.6923955\ttest: 7678.6750044\tbest: 7678.5622884 (9990)\ttotal: 1m 11s\tremaining: 1m 11s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 7676.512082\n",
      "bestIteration = 10335\n",
      "\n",
      "Shrink model to first 10336 iterations.\n",
      "Learning rate set to 0.00888\n",
      "0:\tlearn: 28838.2518122\ttest: 27650.4347993\tbest: 27650.4347993 (0)\ttotal: 5.68ms\tremaining: 1m 53s\n",
      "1000:\tlearn: 7207.1739015\ttest: 11242.2175591\tbest: 11241.0596390 (998)\ttotal: 6.59s\tremaining: 2m 5s\n",
      "2000:\tlearn: 4795.5670470\ttest: 10826.5939743\tbest: 10826.5939743 (2000)\ttotal: 12.8s\tremaining: 1m 55s\n",
      "3000:\tlearn: 3368.9144346\ttest: 10597.7499997\tbest: 10596.3597112 (2993)\ttotal: 19.3s\tremaining: 1m 49s\n",
      "4000:\tlearn: 2489.8837472\ttest: 10456.9269364\tbest: 10456.8748653 (3999)\ttotal: 26.2s\tremaining: 1m 44s\n",
      "5000:\tlearn: 1913.6166565\ttest: 10390.6777206\tbest: 10390.6401512 (4998)\ttotal: 33s\tremaining: 1m 39s\n",
      "6000:\tlearn: 1517.7575683\ttest: 10355.7621248\tbest: 10355.5409321 (5998)\ttotal: 40.3s\tremaining: 1m 33s\n",
      "7000:\tlearn: 1228.5046794\ttest: 10334.8834229\tbest: 10334.2832092 (6979)\ttotal: 47s\tremaining: 1m 27s\n",
      "8000:\tlearn: 1015.0845822\ttest: 10316.7201889\tbest: 10316.7201889 (8000)\ttotal: 54.4s\tremaining: 1m 21s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 10308.02321\n",
      "bestIteration = 8585\n",
      "\n",
      "Shrink model to first 8586 iterations.\n"
     ]
    }
   ],
   "source": [
    "# 타자데이터 도출\n",
    "hitter_performance = pd.concat([rf_model2(X1, y1, X2, y2),\n",
    "                                  lgbm_model2(X1, y1, X2, y2),\n",
    "                                  xgb_model2(X1, y1, X2, y2),\n",
    "                                  cb_model2(X1, y1, X2, y2),\n",
    "                                  knn_model2(X1, y1, X2, y2),\n",
    "                                  regression_model2(X1, y1, X2, y2)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 투수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test 분할\n",
    "col_dict, X1, y1, X2, y2 = Xy_split2(pitcher_fa, pitcher_nonfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's rmse: 29255.7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's rmse: 29044.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's rmse: 52871.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's rmse: 32721.3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's rmse: 20086.4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's rmse: 12235.9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's rmse: 10499.7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[499]\tvalid_0's rmse: 10273.6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's rmse: 9278.44\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's rmse: 13049\n",
      "[0]\ttrain-rmse:70809.35156\teval-rmse:60817.50781\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[7]\ttrain-rmse:10339.03906\teval-rmse:30779.99023\n",
      "\n",
      "[0]\ttrain-rmse:69161.73438\teval-rmse:78532.82812\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[1000]\ttrain-rmse:0.01000\teval-rmse:35724.92578\n",
      "[2000]\ttrain-rmse:0.01000\teval-rmse:35722.93359\n",
      "[3000]\ttrain-rmse:0.01000\teval-rmse:35720.94141\n",
      "[4000]\ttrain-rmse:0.01000\teval-rmse:35718.94922\n",
      "[5000]\ttrain-rmse:0.01000\teval-rmse:35716.95703\n",
      "[6000]\ttrain-rmse:0.01000\teval-rmse:35714.96484\n",
      "[7000]\ttrain-rmse:0.01000\teval-rmse:35712.97266\n",
      "[8000]\ttrain-rmse:0.01000\teval-rmse:35710.98047\n",
      "[9000]\ttrain-rmse:0.01000\teval-rmse:35708.99219\n",
      "[10000]\ttrain-rmse:0.01000\teval-rmse:35707.00000\n",
      "[11000]\ttrain-rmse:0.01000\teval-rmse:35705.00781\n",
      "[12000]\ttrain-rmse:0.01000\teval-rmse:35703.01562\n",
      "[13000]\ttrain-rmse:0.01000\teval-rmse:35701.02344\n",
      "[14000]\ttrain-rmse:0.01000\teval-rmse:35699.03516\n",
      "[15000]\ttrain-rmse:0.01000\teval-rmse:35697.04688\n",
      "[16000]\ttrain-rmse:0.01000\teval-rmse:35695.05469\n",
      "[17000]\ttrain-rmse:0.01000\teval-rmse:35693.06250\n",
      "[18000]\ttrain-rmse:0.01000\teval-rmse:35691.07031\n",
      "[19000]\ttrain-rmse:0.01000\teval-rmse:35689.08203\n",
      "[19999]\ttrain-rmse:0.01000\teval-rmse:35687.08984\n",
      "[0]\ttrain-rmse:64294.88672\teval-rmse:90399.87500\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[4]\ttrain-rmse:21467.28711\teval-rmse:62771.07422\n",
      "\n",
      "[0]\ttrain-rmse:67836.29688\teval-rmse:77318.05469\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "[1000]\ttrain-rmse:0.00925\teval-rmse:34808.86328\n",
      "[2000]\ttrain-rmse:0.00925\teval-rmse:34807.29688\n",
      "[3000]\ttrain-rmse:0.00925\teval-rmse:34805.72656\n",
      "[4000]\ttrain-rmse:0.00925\teval-rmse:34804.16016\n",
      "[5000]\ttrain-rmse:0.00925\teval-rmse:34802.59375\n",
      "[6000]\ttrain-rmse:0.00925\teval-rmse:34801.02734\n",
      "[7000]\ttrain-rmse:0.00925\teval-rmse:34799.45703\n",
      "[8000]\ttrain-rmse:0.00925\teval-rmse:34797.89062\n",
      "[9000]\ttrain-rmse:0.00925\teval-rmse:34796.32422\n",
      "[10000]\ttrain-rmse:0.00925\teval-rmse:34794.75781\n",
      "[11000]\ttrain-rmse:0.00925\teval-rmse:34793.19141\n",
      "[12000]\ttrain-rmse:0.00925\teval-rmse:34791.62500\n",
      "[13000]\ttrain-rmse:0.00925\teval-rmse:34790.05859\n",
      "[14000]\ttrain-rmse:0.00925\teval-rmse:34788.49219\n",
      "[15000]\ttrain-rmse:0.00925\teval-rmse:34786.92578\n",
      "[16000]\ttrain-rmse:0.00925\teval-rmse:34785.36328\n",
      "[17000]\ttrain-rmse:0.00925\teval-rmse:34783.79688\n",
      "[18000]\ttrain-rmse:0.00925\teval-rmse:34782.23047\n",
      "[19000]\ttrain-rmse:0.00925\teval-rmse:34780.66797\n",
      "[19999]\ttrain-rmse:0.00925\teval-rmse:34779.10547\n",
      "[0]\ttrain-rmse:71223.10156\teval-rmse:62509.85938\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[11]\ttrain-rmse:4466.55762\teval-rmse:32776.85547\n",
      "\n",
      "[0]\ttrain-rmse:17856.43945\teval-rmse:19562.42773\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[47]\ttrain-rmse:1201.05933\teval-rmse:12768.90137\n",
      "\n",
      "[0]\ttrain-rmse:17682.25586\teval-rmse:19868.04492\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[9]\ttrain-rmse:3583.01831\teval-rmse:12416.99316\n",
      "\n",
      "[0]\ttrain-rmse:17949.22852\teval-rmse:18563.17383\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[51]\ttrain-rmse:917.38721\teval-rmse:10809.57617\n",
      "\n",
      "[0]\ttrain-rmse:19051.83789\teval-rmse:13021.60449\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[4]\ttrain-rmse:7650.46533\teval-rmse:8037.72705\n",
      "\n",
      "[0]\ttrain-rmse:17483.48047\teval-rmse:21540.79102\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 100 rounds.\n",
      "Stopping. Best iteration:\n",
      "[58]\ttrain-rmse:874.20642\teval-rmse:11928.24805\n",
      "\n",
      "Learning rate set to 0.004106\n",
      "0:\tlearn: 59150.1912871\ttest: 51221.9764251\tbest: 51221.9764251 (0)\ttotal: 3.32ms\tremaining: 1m 6s\n",
      "1000:\tlearn: 15436.3386319\ttest: 33810.1582156\tbest: 33810.1582156 (1000)\ttotal: 2.8s\tremaining: 53.2s\n",
      "2000:\tlearn: 3915.5585509\ttest: 30354.8925311\tbest: 30354.8925311 (2000)\ttotal: 5.26s\tremaining: 47.4s\n",
      "3000:\tlearn: 1288.5216051\ttest: 29588.9485500\tbest: 29588.9485500 (3000)\ttotal: 7.75s\tremaining: 43.9s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 29578.29575\n",
      "bestIteration = 3039\n",
      "\n",
      "Shrink model to first 3040 iterations.\n",
      "Learning rate set to 0.004106\n",
      "0:\tlearn: 59089.1646007\ttest: 51153.8091310\tbest: 51153.8091310 (0)\ttotal: 3.28ms\tremaining: 1m 5s\n",
      "1000:\tlearn: 15868.6838198\ttest: 34357.6161130\tbest: 34357.6161130 (1000)\ttotal: 2.94s\tremaining: 55.8s\n",
      "2000:\tlearn: 4072.0655472\ttest: 32288.0332479\tbest: 32287.3456561 (1995)\ttotal: 5.35s\tremaining: 48.1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 32252.18375\n",
      "bestIteration = 2040\n",
      "\n",
      "Shrink model to first 2041 iterations.\n",
      "Learning rate set to 0.004106\n",
      "0:\tlearn: 51366.9390655\ttest: 77214.3573832\tbest: 77214.3573832 (0)\ttotal: 4.16ms\tremaining: 1m 23s\n",
      "1000:\tlearn: 14538.1586743\ttest: 56612.4678851\tbest: 56612.4678851 (1000)\ttotal: 2.7s\tremaining: 51.3s\n",
      "2000:\tlearn: 3797.7777655\ttest: 54442.5120036\tbest: 54442.4449697 (1999)\ttotal: 4.99s\tremaining: 44.9s\n",
      "3000:\tlearn: 1098.7772797\ttest: 53859.1528832\tbest: 53858.3019028 (2985)\ttotal: 7.27s\tremaining: 41.2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 53803.58849\n",
      "bestIteration = 3277\n",
      "\n",
      "Shrink model to first 3278 iterations.\n",
      "Learning rate set to 0.00412\n",
      "0:\tlearn: 57485.2985917\ttest: 58011.9716319\tbest: 58011.9716319 (0)\ttotal: 2.35ms\tremaining: 47s\n",
      "1000:\tlearn: 15472.5029217\ttest: 36209.9949166\tbest: 36209.9949166 (1000)\ttotal: 3.07s\tremaining: 58.2s\n",
      "2000:\tlearn: 4222.7783340\ttest: 32314.4107547\tbest: 32313.9505794 (1999)\ttotal: 5.68s\tremaining: 51.1s\n",
      "3000:\tlearn: 1300.3957927\ttest: 31156.9560781\tbest: 31156.9560781 (3000)\ttotal: 11.9s\tremaining: 1m 7s\n",
      "4000:\tlearn: 520.9080955\ttest: 30667.9425181\tbest: 30667.9425181 (4000)\ttotal: 17.9s\tremaining: 1m 11s\n",
      "5000:\tlearn: 202.1085486\ttest: 30565.4836685\tbest: 30565.4836685 (5000)\ttotal: 21.3s\tremaining: 1m 3s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 30554.38556\n",
      "bestIteration = 5432\n",
      "\n",
      "Shrink model to first 5433 iterations.\n",
      "Learning rate set to 0.00412\n",
      "0:\tlearn: 60004.4538820\ttest: 45805.0963230\tbest: 45805.0963230 (0)\ttotal: 3.67ms\tremaining: 1m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:\tlearn: 16103.0371750\ttest: 30575.1667676\tbest: 30573.9881815 (999)\ttotal: 2.95s\tremaining: 55.9s\n",
      "2000:\tlearn: 4045.0455414\ttest: 27104.5385329\tbest: 27104.5385329 (2000)\ttotal: 5.34s\tremaining: 48s\n",
      "3000:\tlearn: 1272.0242232\ttest: 26183.5984005\tbest: 26183.5984005 (3000)\ttotal: 7.84s\tremaining: 44.4s\n",
      "4000:\tlearn: 467.5874021\ttest: 26053.3771343\tbest: 26049.7119744 (3936)\ttotal: 10.2s\tremaining: 40.7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 26049.71197\n",
      "bestIteration = 3936\n",
      "\n",
      "Shrink model to first 3937 iterations.\n",
      "Learning rate set to 0.008603\n",
      "0:\tlearn: 21064.7122495\ttest: 22026.7029646\tbest: 22026.7029646 (0)\ttotal: 6.91ms\tremaining: 2m 18s\n",
      "1000:\tlearn: 6129.1739784\ttest: 12921.6585604\tbest: 12920.9858445 (997)\ttotal: 6.95s\tremaining: 2m 11s\n",
      "2000:\tlearn: 4001.4708885\ttest: 12313.2390119\tbest: 12312.4581250 (1999)\ttotal: 13.7s\tremaining: 2m 3s\n",
      "3000:\tlearn: 3050.1731553\ttest: 12174.5155394\tbest: 12174.5155394 (3000)\ttotal: 20.5s\tremaining: 1m 56s\n",
      "4000:\tlearn: 2275.1252017\ttest: 12065.5793133\tbest: 12065.0031741 (3998)\ttotal: 27.5s\tremaining: 1m 49s\n",
      "5000:\tlearn: 1811.2571386\ttest: 12015.6342859\tbest: 12015.2049953 (4985)\ttotal: 34.3s\tremaining: 1m 42s\n",
      "6000:\tlearn: 1499.2234660\ttest: 11977.6152499\tbest: 11977.5447191 (5985)\ttotal: 40.9s\tremaining: 1m 35s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 11973.78422\n",
      "bestIteration = 6154\n",
      "\n",
      "Shrink model to first 6155 iterations.\n",
      "Learning rate set to 0.008603\n",
      "0:\tlearn: 21018.5296012\ttest: 22255.2339400\tbest: 22255.2339400 (0)\ttotal: 10.8ms\tremaining: 3m 35s\n",
      "1000:\tlearn: 6031.7929673\ttest: 11048.3704101\tbest: 11046.8048716 (995)\ttotal: 6.58s\tremaining: 2m 4s\n",
      "2000:\tlearn: 4357.1547920\ttest: 10583.4628104\tbest: 10583.4628104 (2000)\ttotal: 12.7s\tremaining: 1m 54s\n",
      "3000:\tlearn: 3130.7136240\ttest: 10438.4660982\tbest: 10435.3752699 (2953)\ttotal: 19.5s\tremaining: 1m 50s\n",
      "4000:\tlearn: 2362.5216842\ttest: 10375.3115671\tbest: 10373.5407644 (3934)\ttotal: 26.9s\tremaining: 1m 47s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 10373.54076\n",
      "bestIteration = 3934\n",
      "\n",
      "Shrink model to first 3935 iterations.\n",
      "Learning rate set to 0.008603\n",
      "0:\tlearn: 21160.7769135\ttest: 21698.9101906\tbest: 21698.9101906 (0)\ttotal: 6.82ms\tremaining: 2m 16s\n",
      "1000:\tlearn: 6269.3599818\ttest: 11925.1629276\tbest: 11923.6936381 (998)\ttotal: 7.73s\tremaining: 2m 26s\n",
      "2000:\tlearn: 4243.5693579\ttest: 11524.7445321\tbest: 11524.7445321 (2000)\ttotal: 14.6s\tremaining: 2m 11s\n",
      "3000:\tlearn: 3076.7297357\ttest: 11354.5857375\tbest: 11354.5857375 (3000)\ttotal: 21.7s\tremaining: 2m 2s\n",
      "4000:\tlearn: 2306.4264416\ttest: 11294.1563036\tbest: 11294.1334731 (3998)\ttotal: 28.6s\tremaining: 1m 54s\n",
      "5000:\tlearn: 1790.2069228\ttest: 11249.1660653\tbest: 11249.1382887 (4994)\ttotal: 35.4s\tremaining: 1m 46s\n",
      "6000:\tlearn: 1443.7451361\ttest: 11224.6794087\tbest: 11223.7008838 (5920)\ttotal: 42.1s\tremaining: 1m 38s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 11220.85417\n",
      "bestIteration = 6135\n",
      "\n",
      "Shrink model to first 6136 iterations.\n",
      "Learning rate set to 0.008604\n",
      "0:\tlearn: 22606.6165176\ttest: 14747.3553192\tbest: 14747.3553192 (0)\ttotal: 6.25ms\tremaining: 2m 4s\n",
      "1000:\tlearn: 6323.1419545\ttest: 8565.3492862\tbest: 8563.4709307 (998)\ttotal: 7.31s\tremaining: 2m 18s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 8514.14421\n",
      "bestIteration = 1111\n",
      "\n",
      "Shrink model to first 1112 iterations.\n",
      "Learning rate set to 0.008604\n",
      "0:\tlearn: 20404.5894114\ttest: 24416.8363716\tbest: 24416.8363716 (0)\ttotal: 6.13ms\tremaining: 2m 2s\n",
      "1000:\tlearn: 6537.5095599\ttest: 12141.7659214\tbest: 12141.6338415 (999)\ttotal: 6.48s\tremaining: 2m 3s\n",
      "2000:\tlearn: 4414.2899541\ttest: 11439.5151445\tbest: 11439.5151445 (2000)\ttotal: 12.8s\tremaining: 1m 54s\n",
      "3000:\tlearn: 3120.0907823\ttest: 11093.9461873\tbest: 11093.9288060 (2999)\ttotal: 19.2s\tremaining: 1m 48s\n",
      "4000:\tlearn: 2279.9381998\ttest: 10946.5100057\tbest: 10945.4616966 (3992)\ttotal: 25.7s\tremaining: 1m 42s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 10945.4617\n",
      "bestIteration = 3992\n",
      "\n",
      "Shrink model to first 3993 iterations.\n"
     ]
    }
   ],
   "source": [
    "# 타자데이터 도출\n",
    "pitcher_performance = pd.concat([rf_model2(X1, y1, X2, y2),\n",
    "                                  lgbm_model2(X1, y1, X2, y2),\n",
    "                                  xgb_model2(X1, y1, X2, y2),\n",
    "                                  cb_model2(X1, y1, X2, y2),\n",
    "                                  knn_model2(X1, y1, X2, y2),\n",
    "                                  regression_model2(X1, y1, X2, y2)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>knn</th>\n",
       "      <th>regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>16405.411612</td>\n",
       "      <td>15885.514666</td>\n",
       "      <td>17267.666753</td>\n",
       "      <td>14410.175650</td>\n",
       "      <td>22145.011112</td>\n",
       "      <td>23373.294522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>13940.518782</td>\n",
       "      <td>14333.349640</td>\n",
       "      <td>14126.561770</td>\n",
       "      <td>13617.059918</td>\n",
       "      <td>20989.903946</td>\n",
       "      <td>21471.967119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>17999.342629</td>\n",
       "      <td>16865.628321</td>\n",
       "      <td>16986.159356</td>\n",
       "      <td>16479.137359</td>\n",
       "      <td>22706.473249</td>\n",
       "      <td>19416.498183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>10572.543452</td>\n",
       "      <td>10485.271761</td>\n",
       "      <td>10840.332039</td>\n",
       "      <td>9763.495523</td>\n",
       "      <td>18659.826414</td>\n",
       "      <td>16387.649780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv5</th>\n",
       "      <td>13287.946102</td>\n",
       "      <td>13847.791233</td>\n",
       "      <td>13623.967795</td>\n",
       "      <td>12229.562948</td>\n",
       "      <td>20726.940909</td>\n",
       "      <td>18259.758665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균</th>\n",
       "      <td>14441.152515</td>\n",
       "      <td>14283.511124</td>\n",
       "      <td>14568.937543</td>\n",
       "      <td>13299.886280</td>\n",
       "      <td>21045.631126</td>\n",
       "      <td>19781.833654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rf          lgbm           xgb            cb           knn  \\\n",
       "cv1  16405.411612  15885.514666  17267.666753  14410.175650  22145.011112   \n",
       "cv2  13940.518782  14333.349640  14126.561770  13617.059918  20989.903946   \n",
       "cv3  17999.342629  16865.628321  16986.159356  16479.137359  22706.473249   \n",
       "cv4  10572.543452  10485.271761  10840.332039   9763.495523  18659.826414   \n",
       "cv5  13287.946102  13847.791233  13623.967795  12229.562948  20726.940909   \n",
       "평균   14441.152515  14283.511124  14568.937543  13299.886280  21045.631126   \n",
       "\n",
       "       regression  \n",
       "cv1  23373.294522  \n",
       "cv2  21471.967119  \n",
       "cv3  19416.498183  \n",
       "cv4  16387.649780  \n",
       "cv5  18259.758665  \n",
       "평균   19781.833654  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitter_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rf</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>cb</th>\n",
       "      <th>knn</th>\n",
       "      <th>regression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cv1</th>\n",
       "      <td>14177.155631</td>\n",
       "      <td>12807.256778</td>\n",
       "      <td>13571.298772</td>\n",
       "      <td>12577.445725</td>\n",
       "      <td>17013.181034</td>\n",
       "      <td>19211.621909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv2</th>\n",
       "      <td>12283.564973</td>\n",
       "      <td>11184.928287</td>\n",
       "      <td>13439.363937</td>\n",
       "      <td>11247.450432</td>\n",
       "      <td>14161.283073</td>\n",
       "      <td>22176.769228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv3</th>\n",
       "      <td>13950.893091</td>\n",
       "      <td>12650.861876</td>\n",
       "      <td>14510.926725</td>\n",
       "      <td>13491.005187</td>\n",
       "      <td>17734.035519</td>\n",
       "      <td>18047.057972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv4</th>\n",
       "      <td>9522.375130</td>\n",
       "      <td>10230.674634</td>\n",
       "      <td>10074.869743</td>\n",
       "      <td>9420.055243</td>\n",
       "      <td>12295.378325</td>\n",
       "      <td>23426.527546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv5</th>\n",
       "      <td>14095.760095</td>\n",
       "      <td>13216.551739</td>\n",
       "      <td>12678.081934</td>\n",
       "      <td>11416.927473</td>\n",
       "      <td>14427.945003</td>\n",
       "      <td>24092.146305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>평균</th>\n",
       "      <td>12805.949784</td>\n",
       "      <td>12018.054663</td>\n",
       "      <td>12854.908222</td>\n",
       "      <td>11630.576812</td>\n",
       "      <td>15126.364591</td>\n",
       "      <td>21390.824592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               rf          lgbm           xgb            cb           knn  \\\n",
       "cv1  14177.155631  12807.256778  13571.298772  12577.445725  17013.181034   \n",
       "cv2  12283.564973  11184.928287  13439.363937  11247.450432  14161.283073   \n",
       "cv3  13950.893091  12650.861876  14510.926725  13491.005187  17734.035519   \n",
       "cv4   9522.375130  10230.674634  10074.869743   9420.055243  12295.378325   \n",
       "cv5  14095.760095  13216.551739  12678.081934  11416.927473  14427.945003   \n",
       "평균   12805.949784  12018.054663  12854.908222  11630.576812  15126.364591   \n",
       "\n",
       "       regression  \n",
       "cv1  19211.621909  \n",
       "cv2  22176.769228  \n",
       "cv3  18047.057972  \n",
       "cv4  23426.527546  \n",
       "cv5  24092.146305  \n",
       "평균   21390.824592  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitcher_performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
